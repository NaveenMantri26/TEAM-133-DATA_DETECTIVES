{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuNJy2N+gavVxhA2bHc0Pu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NaveenMantri26/TEAM-133-DATA_DETECTIVES/blob/main/AI_Personalized_Learning_Mentor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIbqRNxHGKSL",
        "outputId": "180593be-b497-4fc4-efcf-76a59ec574e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cpu)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.12.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.118.3)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.5)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.8)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers accelerate sentencepiece gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "import gradio as gr\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch"
      ],
      "metadata": {
        "id": "bzDEWuB0GXL6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"google/flan-t5-base\"\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME).to(device)\n",
        "\n",
        "def generate_text(prompt: str, max_new_tokens: int = 256) -> str:\n",
        "    if not prompt.strip():\n",
        "        return \"Please provide a valid input.\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=True,\n",
        "        top_p=0.9,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True).strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIUeKt5BGc6E",
        "outputId": "4683f7b9-2afa-4493-9236-2875014c1046"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In-memory \"database\"\n",
        "students: Dict[str, Dict[str, Any]] = {}\n",
        "\n",
        "TOPICS = [\n",
        "    \"Physics - Newton's Laws\",\n",
        "    \"Mathematics - Quadratic Equations\",\n",
        "    \"Biology - Cell Structure\",\n",
        "    \"Computer Science - Arrays\",\n",
        "    \"Chemistry - Acids and Bases\",\n",
        "]\n",
        "\n",
        "DIFFICULTY_LEVELS = [\"easy\", \"medium\", \"hard\"]\n",
        "\n",
        "def init_student(student_id: str, name: str, level: str = \"beginner\") -> Dict[str, Any]:\n",
        "    if student_id not in students:\n",
        "        students[student_id] = {\n",
        "            \"name\": name,\n",
        "            \"level\": level,\n",
        "            \"current_topic\": None,\n",
        "            \"history\": [],  # list of dicts: {topic, question, correct, difficulty}\n",
        "            \"scores\": {},   # topic -> {\"correct\": x, \"total\": y}\n",
        "            \"last_recommendations\": [],\n",
        "        }\n",
        "    return students[student_id]"
      ],
      "metadata": {
        "id": "NP_eJkG9GqAA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_topic_mastery(student: Dict[str, Any]) -> Dict[str, float]:\n",
        "    mastery = {}\n",
        "    for topic, stats in student[\"scores\"].items():\n",
        "        if stats[\"total\"] > 0:\n",
        "            mastery[topic] = stats[\"correct\"] / stats[\"total\"]\n",
        "        else:\n",
        "            mastery[topic] = 0.0\n",
        "    return mastery\n",
        "\n",
        "def recommend_next_topics(student: Dict[str, Any], top_k: int = 3) -> List[str]:\n",
        "    mastery = get_topic_mastery(student)\n",
        "    # Ensure all topics exist in mastery\n",
        "    for t in TOPICS:\n",
        "        if t not in mastery:\n",
        "            mastery[t] = 0.0\n",
        "    # Sort by lowest mastery (focus on weak areas)\n",
        "    sorted_topics = sorted(mastery.items(), key=lambda x: x[1])\n",
        "    recs = [t[0] for t in sorted_topics[:top_k]]\n",
        "    student[\"last_recommendations\"] = recs\n",
        "    return recs\n",
        "\n",
        "def personalize_learning_path(student_id: str, name: str, level: str) -> str:\n",
        "    student = init_student(student_id, name, level)\n",
        "    recs = recommend_next_topics(student)\n",
        "\n",
        "    path_description = f\"\"\"Personalized Learning Path for {student['name']} ({student['level']} level):\n",
        "\n",
        "1. Start with: {recs[0]}\n",
        "2. Then practice: {recs[1]}\n",
        "3. Finally, strengthen: {recs[2]}\n",
        "\n",
        "The system will adapt difficulty based on your answers and update this path dynamically.\n",
        "\"\"\"\n",
        "    return path_description"
      ],
      "metadata": {
        "id": "knLv9t82Gy2O"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_mcq(topic: str, difficulty: str = \"easy\") -> Dict[str, Any]:\n",
        "    prompt = f\"\"\"\n",
        "Generate ONE multiple-choice question on the topic: {topic}.\n",
        "Difficulty: {difficulty}.\n",
        "Return in this precise format:\n",
        "QUESTION: <question text>\n",
        "A) <option A>\n",
        "B) <option B>\n",
        "C) <option C>\n",
        "D) <option D>\n",
        "ANSWER: <correct option letter>\n",
        "EXPLANATION: <short explanation>\n",
        "\"\"\"\n",
        "    raw = generate_text(prompt, max_new_tokens=256)\n",
        "    question = \"\"\n",
        "    options = {}\n",
        "    answer = \"\"\n",
        "    explanation = \"\"\n",
        "\n",
        "    for line in raw.split(\"\\n\"):\n",
        "        line = line.strip()\n",
        "        if line.startswith(\"QUESTION:\"):\n",
        "            question = line.replace(\"QUESTION:\", \"\").strip()\n",
        "        elif line.startswith(\"A)\"):\n",
        "            options[\"A\"] = line[2:].strip()\n",
        "        elif line.startswith(\"B)\"):\n",
        "            options[\"B\"] = line[2:].strip()\n",
        "        elif line.startswith(\"C)\"):\n",
        "            options[\"C\"] = line[2:].strip()\n",
        "        elif line.startswith(\"D)\"):\n",
        "            options[\"D\"] = line[2:].strip()\n",
        "        elif line.startswith(\"ANSWER:\"):\n",
        "            answer = line.replace(\"ANSWER:\", \"\").strip().upper()[:1]\n",
        "        elif line.startswith(\"EXPLANATION:\"):\n",
        "            explanation = line.replace(\"EXPLANATION:\", \"\").strip()\n",
        "\n",
        "    if answer not in [\"A\", \"B\", \"C\", \"D\"]:\n",
        "        # Fallback if parsing fails\n",
        "        answer = random.choice([\"A\", \"B\", \"C\", \"D\"])\n",
        "\n",
        "    return {\n",
        "        \"topic\": topic,\n",
        "        \"difficulty\": difficulty,\n",
        "        \"question\": question,\n",
        "        \"options\": options,\n",
        "        \"answer\": answer,\n",
        "        \"explanation\": explanation,\n",
        "    }"
      ],
      "metadata": {
        "id": "t2sGeEkjG2f5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_difficulty(student: Dict[str, Any], last_correct: bool, current_difficulty: str) -> str:\n",
        "    idx = DIFFICULTY_LEVELS.index(current_difficulty)\n",
        "    if last_correct and idx < len(DIFFICULTY_LEVELS) - 1:\n",
        "        idx += 1  # move to harder\n",
        "    elif not last_correct and idx > 0:\n",
        "        idx -= 1  # move to easier\n",
        "    return DIFFICULTY_LEVELS[idx]"
      ],
      "metadata": {
        "id": "Hv6d896eG58j"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_student_progress(student_id: str, qa_record: Dict[str, Any]) -> None:\n",
        "    student = students[student_id]\n",
        "    topic = qa_record[\"topic\"]\n",
        "    correct = qa_record[\"correct\"]\n",
        "    difficulty = qa_record[\"difficulty\"]\n",
        "\n",
        "    student[\"history\"].append(qa_record)\n",
        "\n",
        "    if topic not in student[\"scores\"]:\n",
        "        student[\"scores\"][topic] = {\"correct\": 0, \"total\": 0}\n",
        "\n",
        "    student[\"scores\"][topic][\"total\"] += 1\n",
        "    if correct:\n",
        "        student[\"scores\"][topic][\"correct\"] += 1\n",
        "\n",
        "def format_progress_report(student_id: str) -> str:\n",
        "    student = students.get(student_id)\n",
        "    if not student:\n",
        "        return \"No data available for this student yet.\"\n",
        "\n",
        "    mastery = get_topic_mastery(student)\n",
        "    lines = [\n",
        "        f\"Progress Dashboard for {student['name']} ({student['level']} level):\",\n",
        "        \"-\" * 50,\n",
        "    ]\n",
        "\n",
        "    for topic in TOPICS:\n",
        "        m = mastery.get(topic, 0.0)\n",
        "        stats = student[\"scores\"].get(topic, {\"correct\": 0, \"total\": 0})\n",
        "        lines.append(\n",
        "            f\"{topic}: {stats['correct']}/{stats['total']} correct \"\n",
        "            f\"({round(m * 100)}% mastery)\"\n",
        "        )\n",
        "\n",
        "    lines.append(\"\\nRecent Activity:\")\n",
        "    for entry in student[\"history\"][-5:]:\n",
        "        status = \"‚úÖ Correct\" if entry[\"correct\"] else \"‚ùå Wrong\"\n",
        "        lines.append(\n",
        "            f\"- Topic: {entry['topic']} | Diff: {entry['difficulty']} | {status}\"\n",
        "        )\n",
        "\n",
        "    lines.append(\"\\nRecommended Next Topics:\")\n",
        "    if student[\"last_recommendations\"]:\n",
        "        for i, t in enumerate(student[\"last_recommendations\"], 1):\n",
        "            lines.append(f\"{i}. {t}\")\n",
        "    else:\n",
        "        lines.append(\"Recommendations will appear after you attempt some questions.\")\n",
        "\n",
        "    return \"\\n\".join(lines)"
      ],
      "metadata": {
        "id": "YqMFGpMIG90M"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def explain_topic(topic: str, level: str = \"beginner\") -> str:\n",
        "    prompt = f\"\"\"\n",
        "Explain the topic \"{topic}\" to a {level} learner.\n",
        "Use simple language, short paragraphs, and include one real-world example.\n",
        "\"\"\"\n",
        "    return generate_text(prompt, max_new_tokens=256)\n",
        "\n",
        "def chatbot_mentor(student_id: str, message: str) -> str:\n",
        "    student = students.get(student_id)\n",
        "    name = student[\"name\"] if student else \"Student\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are an AI mentor helping a student named {name}.\n",
        "Student profile: {student}.\n",
        "Respond to the student's message with:\n",
        "- Encouraging tone\n",
        "- Clear explanation\n",
        "- If needed, a follow-up question to check understanding\n",
        "\n",
        "Student message: {message}\n",
        "Mentor reply:\n",
        "\"\"\"\n",
        "    return generate_text(prompt, max_new_tokens=256)"
      ],
      "metadata": {
        "id": "2dYzJabhHAui"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll store current MCQ per student in a session dict\n",
        "current_mcq: Dict[str, Dict[str, Any]] = {}\n",
        "current_difficulty_state: Dict[str, str] = {}\n",
        "\n",
        "def start_mcq_session(student_id: str, topic: str) -> Dict[str, Any]:\n",
        "    if student_id not in students:\n",
        "        return {\"error\": \"Please register/login first in the Student Profile tab.\"}\n",
        "\n",
        "    difficulty = current_difficulty_state.get(student_id, \"easy\")\n",
        "    mcq = generate_mcq(topic, difficulty)\n",
        "    current_mcq[student_id] = mcq\n",
        "    students[student_id][\"current_topic\"] = topic\n",
        "    return mcq\n",
        "\n",
        "def grade_mcq_answer(student_id: str, selected_option: str) -> str:\n",
        "    if student_id not in current_mcq:\n",
        "        return \"No active question. Please start a quiz first.\"\n",
        "\n",
        "    mcq = current_mcq[student_id]\n",
        "    correct = (selected_option == mcq[\"answer\"])\n",
        "    feedback = \"Correct! üéâ\" if correct else f\"Incorrect. The correct answer is {mcq['answer']}.\"\n",
        "\n",
        "    qa_record = {\n",
        "        \"topic\": mcq[\"topic\"],\n",
        "        \"question\": mcq[\"question\"],\n",
        "        \"selected\": selected_option,\n",
        "        \"correct_answer\": mcq[\"answer\"],\n",
        "        \"correct\": correct,\n",
        "        \"difficulty\": mcq[\"difficulty\"],\n",
        "        \"timestamp\": time.time(),\n",
        "    }\n",
        "    update_student_progress(student_id, qa_record)\n",
        "\n",
        "    # Adjust difficulty\n",
        "    new_diff = adjust_difficulty(students[student_id], correct, mcq[\"difficulty\"])\n",
        "    current_difficulty_state[student_id] = new_diff\n",
        "\n",
        "    explanation = mcq.get(\"explanation\", \"No explanation available.\")\n",
        "    return f\"\"\"{feedback}\n",
        "\n",
        "Explanation: {explanation}\n",
        "\n",
        "Next question will be at '{new_diff}' difficulty based on your performance.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "IAbjPgN2HDla"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ui_register_student(student_id: str, name: str, level: str):\n",
        "    if not student_id.strip() or not name.strip():\n",
        "        return \"Student ID and Name are required.\"\n",
        "    student = init_student(student_id.strip(), name.strip(), level)\n",
        "    return f\"Profile loaded for {student['name']} (Level: {student['level']}). You can now use all other tabs.\"\n",
        "\n",
        "def ui_get_learning_path(student_id: str, name: str, level: str):\n",
        "    if not student_id.strip() or not name.strip():\n",
        "        return \"Please provide Student ID and Name.\"\n",
        "    return personalize_learning_path(student_id.strip(), name.strip(), level)\n",
        "\n",
        "def ui_start_quiz(student_id: str, topic: str):\n",
        "    student_id = student_id.strip()\n",
        "    if not student_id:\n",
        "        return \"Student ID required.\", \"\", \"\", \"\", \"\", \"\"\n",
        "    result = start_mcq_session(student_id, topic)\n",
        "    if \"error\" in result:\n",
        "        return result[\"error\"], \"\", \"\", \"\", \"\", \"\"\n",
        "    q = result[\"question\"]\n",
        "    A = result[\"options\"].get(\"A\", \"\")\n",
        "    B = result[\"options\"].get(\"B\", \"\")\n",
        "    C = result[\"options\"].get(\"C\", \"\")\n",
        "    D = result[\"options\"].get(\"D\", \"\")\n",
        "    info = f\"Topic: {result['topic']} | Difficulty: {result['difficulty']}\"\n",
        "    return info, q, A, B, C, D\n",
        "\n",
        "def ui_submit_answer(student_id: str, selected_option: str):\n",
        "    student_id = student_id.strip()\n",
        "    if not student_id:\n",
        "        return \"Student ID required.\"\n",
        "    if not selected_option:\n",
        "        return \"Please select an option (A/B/C/D).\"\n",
        "    return grade_mcq_answer(student_id, selected_option)\n",
        "\n",
        "def ui_explain_topic(student_id: str, topic: str, level: str):\n",
        "    if not topic.strip():\n",
        "        return \"Please select or enter a topic.\"\n",
        "    return explain_topic(topic.strip(), level)\n",
        "\n",
        "def ui_show_progress(student_id: str):\n",
        "    student_id = student_id.strip()\n",
        "    if not student_id:\n",
        "        return \"Student ID required.\"\n",
        "    if student_id not in students:\n",
        "        return \"No profile found. Please register first.\"\n",
        "    # Refresh recommendations\n",
        "    recommend_next_topics(students[student_id])\n",
        "    return format_progress_report(student_id)\n",
        "\n",
        "def ui_chat_with_mentor(student_id: str, message: str):\n",
        "    student_id = student_id.strip()\n",
        "    if not message.strip():\n",
        "        return \"Please enter a question or message.\"\n",
        "    if student_id not in students:\n",
        "        # Create a temporary generic profile\n",
        "        init_student(student_id or \"guest\", \"Guest\", \"beginner\")\n",
        "    return chatbot_mentor(student_id or \"guest\", message)"
      ],
      "metadata": {
        "id": "et4TQ1gEHGK2"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks(title=\"AI-Powered Personalized Learning Mentor\") as demo:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "# üéì AI‚ÄëPowered Personalized Learning Mentor with Adaptive Assessments\n",
        "**Features:** Personalized learning path, adaptive MCQs, difficulty adjustment, student tracking, topic explanations, progress dashboard, recommendations, and chatbot mentor.\n",
        "\"\"\"\n",
        "    )\n",
        "\n",
        "    with gr.Tab(\"1Ô∏è‚É£ Student Profile & Learning Path\"):\n",
        "        gr.Markdown(\"### Register / Load Student Profile\")\n",
        "        with gr.Row():\n",
        "            student_id_reg = gr.Textbox(label=\"Student ID\", placeholder=\"e.g., stu_101\")\n",
        "            name_reg = gr.Textbox(label=\"Name\", placeholder=\"Your name\")\n",
        "        level_reg = gr.Radio(\n",
        "            choices=[\"beginner\", \"intermediate\", \"advanced\"],\n",
        "            value=\"beginner\",\n",
        "            label=\"Level\"\n",
        "        )\n",
        "        btn_register = gr.Button(\"Save / Load Profile\")\n",
        "        reg_output = gr.Textbox(label=\"Status\")\n",
        "\n",
        "        gr.Markdown(\"### Personalized Learning Path\")\n",
        "        btn_path = gr.Button(\"Generate / Update Learning Path\")\n",
        "        path_output = gr.Textbox(label=\"Learning Path\", lines=8)\n",
        "\n",
        "        btn_register.click(\n",
        "            ui_register_student,\n",
        "            inputs=[student_id_reg, name_reg, level_reg],\n",
        "            outputs=reg_output\n",
        "        )\n",
        "\n",
        "        btn_path.click(\n",
        "            ui_get_learning_path,\n",
        "            inputs=[student_id_reg, name_reg, level_reg],\n",
        "            outputs=path_output\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"2Ô∏è‚É£ Adaptive MCQ Quiz\"):\n",
        "        gr.Markdown(\"### Start Adaptive Quiz\")\n",
        "        student_id_quiz = gr.Textbox(label=\"Student ID (same as Profile)\")\n",
        "        topic_quiz = gr.Dropdown(choices=TOPICS, label=\"Select Topic\")\n",
        "        btn_start_quiz = gr.Button(\"Start / Next Question\")\n",
        "\n",
        "        quiz_info = gr.Textbox(label=\"Question Meta\", interactive=False)\n",
        "        quiz_question = gr.Textbox(label=\"Question\", lines=4, interactive=False)\n",
        "        with gr.Row():\n",
        "            opt_A = gr.Textbox(label=\"A\", interactive=False)\n",
        "            opt_B = gr.Textbox(label=\"B\", interactive=False)\n",
        "        with gr.Row():\n",
        "            opt_C = gr.Textbox(label=\"C\", interactive=False)\n",
        "            opt_D = gr.Textbox(label=\"D\", interactive=False)\n",
        "\n",
        "        selected_option = gr.Radio(\n",
        "            choices=[\"A\", \"B\", \"C\", \"D\"],\n",
        "            label=\"Your Answer\"\n",
        "        )\n",
        "        btn_submit = gr.Button(\"Submit Answer\")\n",
        "        feedback_output = gr.Textbox(label=\"Feedback\", lines=6)\n",
        "\n",
        "        btn_start_quiz.click(\n",
        "            ui_start_quiz,\n",
        "            inputs=[student_id_quiz, topic_quiz],\n",
        "            outputs=[quiz_info, quiz_question, opt_A, opt_B, opt_C, opt_D]\n",
        "        )\n",
        "\n",
        "        btn_submit.click(\n",
        "            ui_submit_answer,\n",
        "            inputs=[student_id_quiz, selected_option],\n",
        "            outputs=feedback_output\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"3Ô∏è‚É£ Topic Explanations\"):\n",
        "        gr.Markdown(\"### Get Topic-wise Explanation\")\n",
        "        student_id_explain = gr.Textbox(label=\"Student ID (optional)\")\n",
        "        topic_explain = gr.Dropdown(\n",
        "            choices=TOPICS + [\"Custom Topic\"],\n",
        "            label=\"Select Topic\"\n",
        "        )\n",
        "        custom_topic = gr.Textbox(\n",
        "            label=\"If 'Custom Topic', type here\",\n",
        "            placeholder=\"e.g., Pointers in C, Photosynthesis, etc.\"\n",
        "        )\n",
        "        level_explain = gr.Radio(\n",
        "            choices=[\"beginner\", \"intermediate\", \"advanced\"],\n",
        "            value=\"beginner\",\n",
        "            label=\"Explanation Level\"\n",
        "        )\n",
        "        btn_explain = gr.Button(\"Explain Topic\")\n",
        "        explanation_output = gr.Textbox(label=\"Explanation\", lines=10)\n",
        "\n",
        "        def resolve_topic(selected, custom):\n",
        "            if selected == \"Custom Topic\":\n",
        "                return custom\n",
        "            return selected\n",
        "\n",
        "        btn_explain.click(\n",
        "            lambda sid, sel, custom, lvl: ui_explain_topic(sid, resolve_topic(sel, custom), lvl),\n",
        "            inputs=[student_id_explain, topic_explain, custom_topic, level_explain],\n",
        "            outputs=explanation_output\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"4Ô∏è‚É£ Progress Dashboard & Recommendations\"):\n",
        "        gr.Markdown(\"### View Your Progress and Recommendations\")\n",
        "        student_id_progress = gr.Textbox(label=\"Student ID\")\n",
        "        btn_progress = gr.Button(\"Show Progress\")\n",
        "        progress_output = gr.Textbox(label=\"Progress & Recommendations\", lines=15)\n",
        "\n",
        "        btn_progress.click(\n",
        "            ui_show_progress,\n",
        "            inputs=student_id_progress,\n",
        "            outputs=progress_output\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"5Ô∏è‚É£ Chatbot Mentor\"):\n",
        "        gr.Markdown(\"### Ask Your AI Mentor Anything\")\n",
        "        student_id_chat = gr.Textbox(label=\"Student ID (optional, for personalization)\")\n",
        "        chat_input = gr.Textbox(label=\"Your Question / Doubt\")\n",
        "        btn_chat = gr.Button(\"Ask Mentor\")\n",
        "        chat_output = gr.Textbox(label=\"Mentor Reply\", lines=10)\n",
        "\n",
        "        btn_chat.click(\n",
        "            ui_chat_with_mentor,\n",
        "            inputs=[student_id_chat, chat_input],\n",
        "            outputs=chat_output\n",
        "        )\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "BXEgyCroHJgU",
        "outputId": "61677409-9fe8-4d6a-c28c-fcac46eb6c86"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://271e3785fd832ca910.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://271e3785fd832ca910.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NuvuyImVHNUe"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}